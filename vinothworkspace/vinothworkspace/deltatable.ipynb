{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20742a13-820e-41d0-9dd7-ce3120d7b153",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Importing Libraries"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
    "from pyspark.sql.functions import col,lit,explode,posexplode\n",
    "from delta.tables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfad95b4-93c3-4a85-8cf3-94fdcd32d0a0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Creating delta table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create schema if not exists emp;\n",
    "create or replace table emp.employee1\n",
    "(\n",
    "  id int,\n",
    "  name string,\n",
    "  dob int\n",
    ")using delta\n",
    "location '/FileStore/tables/employee1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06cd52e1-d3b6-4612-9d85-1910a58ed4a6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Inserting values to table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "insert into emp.employee1 values(1,'Vinoth',1988),(2,'Sathya',1994);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21ecef92-0197-45d7-8460-892943723ea2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Checking history of table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from emp.employee1;\n",
    "--describe history emp.employee1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "296dd959-ee16-4df3-ba50-b466aad55031",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Creating Deltainstance for DeltaTable"
    }
   },
   "outputs": [],
   "source": [
    "dt = DeltaTable.forName(spark,\"emp.employee1\")\n",
    "dt.toDF().display()\n",
    "dt.history().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "296d475d-35a4-45ae-8f2b-85852396b634",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Creating DataFrame"
    }
   },
   "outputs": [],
   "source": [
    "emp_schema = StructType([StructField(\"id\",IntegerType(),True),\n",
    "                         StructField(\"name\",StringType(),True),\n",
    "                         StructField(\"dob\",IntegerType(),True)\n",
    "                         ])\n",
    "emp_data = [(1,\"Vinoth Sakkaraivel\",1988),\n",
    "            (3,\"Thanu\",2016),\n",
    "            (4,\"Sirpiga\",2021)]\n",
    "\n",
    "df = spark.createDataFrame(emp_data,emp_schema)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e8908db-d2c6-4246-9fea-da80cf59e710",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Merging the rows"
    }
   },
   "outputs": [],
   "source": [
    "#dt.alias(\"t\").merge(df.alias(\"s\"),\"t.id = s.id\").whenMatchedUpdate(set= {\"t.id\":\"s.id\",\"t.name\":\"s.name\",\"t.dob\":\"s.dob\"}).execute()\n",
    "dt.alias(\"t\").merge(df.alias(\"s\"),\"t.id = s.id\").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "dt.toDF().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5dc208e-259d-4a01-9aad-65cd07fd81bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from emp.employee1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df17277d-2b2e-487a-b8ec-ac58f8de7109",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dbutils.fs.mkdirs(\"/FileStore/tables/audit_log1\")\n",
    "#dbutils.fs.rm(\"/FileStore/tables/audit_log\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80cb67cf-4715-40b3-8877-7ee925eb4f86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create table if not exists emp.audit_log1\n",
    "(\n",
    "  operation string,\n",
    "  update_time timestamp,\n",
    "  user_name string,\n",
    "  notebook_name string,\n",
    "  numTargetRowsUpdated int,\n",
    "  numTargetRowsInserted int,\n",
    "  numTargetRowDeleted int\n",
    ")using delta\n",
    "location '/FileStore/tables/audit_log1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7493073-927e-4f6e-8432-b760f52bc9f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dt_AL = DeltaTable.forName(spark,\"emp.audit_log1\")\n",
    "dt_AL.toDF().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfa25e5a-a399-44cf-9136-3be9297aacd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = dt.history(1)\n",
    "df1.display()\n",
    "df2 = df1.filter((df1.operation == 'MERGE') | (df1.operation == 'WRITE'))\n",
    "df3 = df2.select(df2.operation.alias('opn'),df2.timestamp,df2.userName)\n",
    "df3.display()\n",
    "df4 = df2.select(df2.operation,explode(df2.operationMetrics))\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42c0ed8b-e625-4adc-89fb-36cb69aa5d9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce\n",
    "df5 = df4.select(df4.operation,df4.key,df4.value.cast(\"int\"))\n",
    "display(df5)\n",
    "df6 = df5.groupBy(\"operation\").pivot(\"key\").sum(\"value\")\n",
    "display(df6)\n",
    "df7 = df6.select(df6.operation,coalesce(col(\"numTargetRowsInserted\"),lit(0)).alias('numTargetRowsInserted'),df6.numTargetRowsUpdated,df6.numTargetRowsDeleted)\n",
    "display(df7)\n",
    "df8 = df7.join(df3,df7.operation == df3.opn,\"inner\")\n",
    "notebookname = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get().split(\"/\")[-1]\n",
    "df9 = df8.withColumn(\"NotebookName\",lit(notebookname))\n",
    "df9.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b302bb0-5d4b-4679-a0fd-df9626ec6318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "MERGE into emp.audit_log1 as t using tmp_auditlog as s\n",
    "ON t.operation = s.opn WHEN MATCHED THEN UPDATE SET \n",
    "t.operation = s.opn,t.update_time = s.timestamp, t.user_name = s.userName, t.notebook_name = s.NotebookName,\n",
    "t.numTargetRowsUpdated = s.numTargetRowsUpdated, t.numTargetRowsInserted = s.numTargetRowsInserted, t.numTargetRowDeleted = s.numTargetRowsDeleted \n",
    "WHEN NOT MATCHED THEN\n",
    "INSERT (t.operation,t.update_time,t.user_name,t.notebook_name,t.numTargetRowsUpdated,t.numTargetRowsInserted,t.numTargetRowDeleted) \n",
    "VALUES (s.opn,s.timestamp, s.userName, s.NotebookName,s.numTargetRowsUpdated,s.numTargetRowsInserted,s.numTargetRowsDeleted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47ec89a4-57ce-40fc-a8b0-4cd29cbe62ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from tmp_auditlog;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ed5650e-8791-4b99-8f0f-9cdd7456e065",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df9.createOrReplaceTempView('tmp_auditlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0173f00d-2f6c-45b0-a2f8-49b39875d86e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from emp.audit_log1"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 896380610065841,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "deltatable",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
